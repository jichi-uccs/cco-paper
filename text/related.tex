\section{Related Work}
\label{sec-related}

In order to enhance the efficiency of MPI applications, existing work
has focused mostly on communication mechanisms underlying the wide
variety of MPI operations, for example, alternative protocols for
point-to-point MPI
communications~\cite{brightwell:eurompi03,denis:eurompi11}, collective
operations~\cite{traff:eurompi14:ocd,traff:eurompi14:mcd,graham:eurompi08,mittal:ppopp12},
remote direct memory access
(RDMA)~\cite{liu:ics03,woodall:eurompi06,hatanaka:eurompi13}, load
balancing of the operations~\cite{nian:niss09,kale:eurompi14}, and the
elimination of redundant communications through software caching and
the exploitation of data
locality~\cite{buntinas:icpp09,isujita:eurompi14,ozog:ics13}.  In
contrast, our work focuses on application-level performance
enhancement by enabling automated overlapping of MPI communications
with independent local computations.

Iancu et al.~\cite{iancu:ppopp07} tried to automatically determine
message sizes and schedules for MPI communications through an
analytical model of system scale and load to avoid network congestion.
Danalis et al.~\cite{danalis:ics09} investigated compiler
optimizations to potentially automate the overlapping of MPI
computations and communications, by formulating a set of data flow
equations to describe the side effects of key MPI operations so that
an MPI-aware compiler can automatically assess the safety of several
optimizations, which were then manually applied in their paper.
Various patterns of computation-communication overlapping and
automated optimization schemes have also been
discussed~\cite{danalis:sc05,fishgold:ipdps06}.  In contrast, we
present a systematic approach to enable a pattern of loop-based
communication-computation overlapping in scientific applications,
including automated identification of optimization opportunities and a
semi-automated implementation to perform the optimizations using hot
path analysis, dependence analysis, and empirical tuning to determine
where and how to apply the optimizations.


To reason about the profitability of optimizing MPI applications,
Sancho et al.~\cite{sancho:sc06} combined empirical tuning with
networking models to quantify the potential benefit of overlapping
communication and computation in large-scale scientific applications.
Potluri et al.~\cite{potluri:ics10} empirically quantified the
overlapping of MPI-2 operations in a seismic modeling application.  Hu
et al.~\cite{hu:npc08,song:ppopp14} identified the consumer-producer
model from the control flow graph of the application to guide
optimization decisions for overlapping Alltoall communication in a 3-D
FFT.  Didelot et al.~\cite{didelot:imc14,didelot:eurompi12} developed
a message progression model based on collaborative polling that allows
an efficient autoadaptive overlapping of communication phases with
computation.  In this paper, we predicted the most time-consuming
\emph{hot} code path of the computation-communication patterns to
optimize, using existing analytical model of
communications~\cite{loggp}.

Preissl et al.~\cite{preissl:tms10} summarized common communication
patterns in MPI applications to enable automated optimization.
Pellegrini et al.~\cite{pellegrini:eurompi12} proposed an exact
dependence analysis approach for increasing the overlapping of
computation and communication.  Subotic et al.~\cite{subotic:hipeac08}
speculatively extracted runtime data-flow to understand the dynamic
dependence of the application.  Aananthakrishnan et
al.~\cite{aananthakrishnan:ics13} used a hybrid static and runtime
data-flow analysis of MPI programs.  We also use dependence analysis
to determine the safety of optimization, enhanced with additional
knowledge from developers about the MPI operations and runtime code
paths within their applications.

In order to find the optimal placement of nonblocking MPI operations
within the computation control flow, accurate modeling of the
underlying computation and communication is
required~\cite{brightwell:ics04}.  Hoefler et
al.~\cite{hoefler:icppw05} presented an analytical approach to model
MPI barriers.  Ino et al.~\cite{ino:ppopp2001} presented a parallel
computational model for synchronization analysis in MPI.  Martinez et
al.~\cite{martinez:ipdps09} developed an analytical model extending
LogGP~\cite{loggp} for accurate estimation of individual MPI
communication.  Moritz and Frank~\cite{moritz:tpds01} modeled network
contention in MPI applications.  In our optimization, we first
reposition each pair of local computation and nonblocking
communication as far apart as safety allows across different loop
iterations and insert MPI\_Test with empirically tuned frequencies
into the local computation to ensure proper progress of the
nonblocking communication.
